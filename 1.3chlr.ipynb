{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n",
    "                           roc_auc_score, roc_curve, classification_report, confusion_matrix, auc)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcode parameters instead of using command line arguments\n",
    "needle_height = '1.3'\n",
    "conjugate = 'chlr'\n",
    "n_trials = 50\n",
    "dataset_key = f\"{needle_height}_{conjugate}\"\n",
    "\n",
    "# Create output directory with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"results/{dataset_key}_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Base directory\n",
    "base_dir = r\"D:\\20241129_solid_nN_1.3_2.4_mdck_siRNA_tnsfn_chlr\"\n",
    "\n",
    "# Define dataset path directly for 1.3_chlr\n",
    "dataset_path = base_dir + r\"\\20241129_solid_nN_1.3_mdck_chlr_dataset\\solid_1.3_chlr_cell_level.csv\"\n",
    "\n",
    "# Define morphological and intensity features\n",
    "cell_morph_features = [\n",
    "    'area', 'perimeter', 'major_axis_length', 'minor_axis_length', \n",
    "    'eccentricity', 'circularity', 'solidity', 'orientation'\n",
    "]\n",
    "\n",
    "nuclear_morph_features = [\n",
    "    'nuclear_area', 'nuclear_perimeter', 'nuclear_major_axis_length', \n",
    "    'nuclear_minor_axis_length', 'nuclear_eccentricity', 'nuclear_circularity', \n",
    "    'nuclear_solidity', 'nuclear_orientation'\n",
    "]\n",
    "\n",
    "channel_feature_suffixes = [\n",
    "    'intensity_p10', 'intensity_p25', 'intensity_p50', \n",
    "    'intensity_p75', 'intensity_p90'\n",
    "]\n",
    "\n",
    "protein_channels = ['actin', 'caveolin', 'clathrin_hc', 'nuclei']\n",
    "\n",
    "# Generate feature list with caveolin features first to ensure dominance\n",
    "feature_list = cell_morph_features + nuclear_morph_features\n",
    "\n",
    "for suffix in channel_feature_suffixes:\n",
    "    feature_list.append(f\"caveolin_{suffix}\")\n",
    "\n",
    "for ch in protein_channels:\n",
    "    if ch != 'caveolin':\n",
    "        for suffix in channel_feature_suffixes:\n",
    "            feature_list.append(f\"{ch}_{suffix}\")\n",
    "\n",
    "def process_dataset(dataset_path, dataset_name, area_percentiles=(2, 98)):\n",
    "    print(f\"\\n=== Processing {dataset_name} ===\")\n",
    "    \n",
    "    # Extract conjugate type from dataset_name\n",
    "    conjugate_type = dataset_name.split('_')[1] # Will be 'chlr'\n",
    "    \n",
    "    # Set the correct intensity column name\n",
    "    intensity_column = f\"{conjugate_type}_intensity_mean\"\n",
    "    \n",
    "    print(f\"Using intensity column: {intensity_column}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    \n",
    "    # Determine threshold for chlr\n",
    "    intensity_threshold = 300\n",
    "    \n",
    "    # Apply area filtering based on percentiles\n",
    "    cell_area_min, cell_area_max = np.percentile(df['area'], area_percentiles)\n",
    "    nuclear_area_min, nuclear_area_max = np.percentile(df['nuclear_area'], area_percentiles)\n",
    "    \n",
    "    # Filter cells and nuclei based on thresholds\n",
    "    df_filtered = df[\n",
    "        (df['area'] >= cell_area_min) & \n",
    "        (df['area'] <= cell_area_max) & \n",
    "        (df[intensity_column] > intensity_threshold)\n",
    "    ].copy()\n",
    "    \n",
    "    nuclei_threshold = (\n",
    "        (df_filtered['nuclear_area'] >= nuclear_area_min) & \n",
    "        (df_filtered['nuclear_area'] <= nuclear_area_max)\n",
    "    )\n",
    "    \n",
    "    nuclear_cols = [col for col in df_filtered.columns if col.startswith('nuclear_')]\n",
    "    df_filtered.loc[~nuclei_threshold, nuclear_cols] = np.nan\n",
    "    \n",
    "    # Convert target into categorical bins\n",
    "    num_bins = 5\n",
    "    df_filtered['conjugate_category'] = pd.qcut(df_filtered[intensity_column], q=num_bins, labels=False)\n",
    "    \n",
    "    y = df_filtered['conjugate_category']\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    X = df_filtered[feature_list]\n",
    "    \n",
    "    images = df_filtered['image_id']\n",
    "    \n",
    "    # Initialize storage for aggregated metrics\n",
    "    all_fold_metrics = []\n",
    "    class_report_list = []\n",
    "    shap_values_list = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    \n",
    "    # Track class distributions\n",
    "    class_distributions = []\n",
    "    \n",
    "    # Outer CV: Stratified Group K-Fold\n",
    "    outer_cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Create a dummy model for SHAP initialization\n",
    "    dummy_model = xgb.XGBClassifier()\n",
    "    dummy_model.fit(X.iloc[:10], y_encoded[:10])\n",
    "    explainer = shap.TreeExplainer(dummy_model)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y_encoded, groups=images), start=1):\n",
    "        print(f\"\\n=== Outer Fold {fold} ===\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "        \n",
    "        # Track class distribution in this fold\n",
    "        class_distributions.append({\n",
    "            \"train\": np.bincount(y_train, minlength=num_bins),\n",
    "            \"test\": np.bincount(y_test, minlength=num_bins)\n",
    "        })\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 200)\n",
    "            }\n",
    "            \n",
    "            model = xgb.XGBClassifier(random_state=42, **params)\n",
    "            \n",
    "            inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            inner_scores = []\n",
    "            \n",
    "            for inner_train_idx, inner_valid_idx in inner_cv.split(X_train_scaled, y_train):\n",
    "                X_inner_train = X_train_scaled[inner_train_idx]\n",
    "                X_inner_valid = X_train_scaled[inner_valid_idx]\n",
    "                y_inner_train = y_train[inner_train_idx]\n",
    "                y_inner_valid = y_train[inner_valid_idx]\n",
    "                \n",
    "                model.fit(X_inner_train, y_inner_train)\n",
    "                y_pred_inner = model.predict(X_inner_valid)\n",
    "                score = accuracy_score(y_inner_valid, y_pred_inner)\n",
    "                inner_scores.append(score)\n",
    "            \n",
    "            return np.mean(inner_scores)\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        \n",
    "        best_model = xgb.XGBClassifier(random_state=42, **best_params)\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # After model training, calculate comprehensive metrics\n",
    "        y_test_pred = best_model.predict(X_test_scaled)\n",
    "        y_test_proba = best_model.predict_proba(X_test_scaled)\n",
    "        \n",
    "        # Store fold metrics\n",
    "        fold_metrics = {\n",
    "            \"fold\": fold,\n",
    "            \"accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "            \"f1_weighted\": f1_score(y_test, y_test_pred, average='weighted'),\n",
    "            \"precision_weighted\": precision_score(y_test, y_test_pred, average='weighted'),\n",
    "            \"recall_weighted\": recall_score(y_test, y_test_pred, average='weighted'),\n",
    "            \"roc_auc\": roc_auc_score(y_test, y_test_proba, multi_class='ovr')\n",
    "        }\n",
    "        all_fold_metrics.append(fold_metrics)\n",
    "        \n",
    "        # Generate class-wise metrics\n",
    "        class_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        class_report_list.append(class_report)\n",
    "        \n",
    "        # Calculate SHAP values\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        shap_values_list.append(shap_values)\n",
    "        \n",
    "        # Plot ROC curves for each class\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i in range(len(np.unique(y_encoded))):\n",
    "            if i < len(y_test_proba[0]): # Ensure class exists in predictions\n",
    "                fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_test_proba[:, i])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "                \n",
    "                # Store for aggregate ROC\n",
    "                if i == 0: # Main class of interest\n",
    "                    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "                    interp_tpr[0] = 0.0\n",
    "                    tprs.append(interp_tpr)\n",
    "                    aucs.append(roc_auc)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Per-Class ROC Curves - Fold {fold}')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{output_dir}/per_class_roc_fold_{fold}_{dataset_name}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - Fold {fold}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f\"{output_dir}/confusion_matrix_fold_{fold}_{dataset_name}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Feature-target correlation analysis\n",
    "        correlation_df = X_test.copy()\n",
    "        correlation_df['target'] = y_test\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        corr_with_target = correlation_df.corr()['target'].sort_values(ascending=False)\n",
    "        sns.heatmap(pd.DataFrame(corr_with_target).T, annot=True, cmap='coolwarm')\n",
    "        plt.title(f'Feature-Target Correlations - Fold {fold}')\n",
    "        plt.savefig(f\"{output_dir}/feature_target_corr_fold_{fold}_{dataset_name}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # SHAP summary plot for this fold\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "        plt.title(f'SHAP Feature Importance - Fold {fold}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/shap_summary_fold_{fold}_{dataset_name}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Feature importance plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        xgb.plot_importance(best_model, max_num_features=20)\n",
    "        plt.title(f\"Feature Importance - {conjugate_type.upper()} - Fold {fold}\")\n",
    "        plt.savefig(f\"{output_dir}/feature_importance_{conjugate_type}_fold_{fold}_{dataset_name}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Save model\n",
    "        model_filename = f\"{output_dir}/model_{dataset_name}_fold_{fold}.joblib\"\n",
    "        joblib.dump(best_model, model_filename)\n",
    "        print(f\"Model saved as {model_filename}\")\n",
    "    \n",
    "    # After all folds complete:\n",
    "    # 1. Aggregate performance metrics\n",
    "    metrics_df = pd.DataFrame(all_fold_metrics)\n",
    "    avg_metrics = {\n",
    "        'accuracy': metrics_df['accuracy'].mean(),\n",
    "        'accuracy_std': metrics_df['accuracy'].std(),\n",
    "        'f1_weighted': metrics_df['f1_weighted'].mean(),\n",
    "        'f1_weighted_std': metrics_df['f1_weighted'].std(),\n",
    "        'precision_weighted': metrics_df['precision_weighted'].mean(),\n",
    "        'precision_weighted_std': metrics_df['precision_weighted'].std(),\n",
    "        'recall_weighted': metrics_df['recall_weighted'].mean(),\n",
    "        'recall_weighted_std': metrics_df['recall_weighted'].std(),\n",
    "        'roc_auc': metrics_df['roc_auc'].mean(),\n",
    "        'roc_auc_std': metrics_df['roc_auc'].std()\n",
    "    }\n",
    "    \n",
    "    # 2. Generate aggregate ROC curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot individual fold ROC curves (faded)\n",
    "    for i, tpr in enumerate(tprs):\n",
    "        plt.plot(mean_fpr, tpr, alpha=0.3, label=f'ROC fold {i+1} (AUC = {aucs[i]:.2f})')\n",
    "    \n",
    "    # Plot mean ROC\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'b-', label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})', lw=2)\n",
    "    \n",
    "    # Plot standard deviation\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.2, label=r'± 1 std. dev.')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Aggregate ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"{output_dir}/aggregate_roc_{dataset_name}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Class distribution analysis\n",
    "    class_df = pd.DataFrame()\n",
    "    for fold, dist in enumerate(class_distributions, 1):\n",
    "        fold_df = pd.DataFrame({\n",
    "            'fold': fold,\n",
    "            'class': range(len(dist['train'])),\n",
    "            'train_count': dist['train'],\n",
    "            'test_count': dist['test']\n",
    "        })\n",
    "        class_df = pd.concat([class_df, fold_df])\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='class', y='train_count', data=class_df)\n",
    "    plt.title('Class Distribution Across Folds (Train)')\n",
    "    plt.savefig(f\"{output_dir}/class_distribution_train_{dataset_name}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Run the analysis for 1.3_chlr only\n",
    "avg_metrics = process_dataset(dataset_path, dataset_key)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"Dataset: {dataset_key}\")\n",
    "print(f\"Accuracy: {avg_metrics['accuracy']:.4f} ± {avg_metrics['accuracy_std']:.4f}\")\n",
    "print(f\"F1 Score (weighted): {avg_metrics['f1_weighted']:.4f} ± {avg_metrics['f1_weighted_std']:.4f}\")\n",
    "print(f\"Precision (weighted): {avg_metrics['precision_weighted']:.4f} ± {avg_metrics['precision_weighted_std']:.4f}\")\n",
    "print(f\"Recall (weighted): {avg_metrics['recall_weighted']:.4f} ± {avg_metrics['recall_weighted_std']:.4f}\")\n",
    "print(f\"ROC AUC: {avg_metrics['roc_auc']:.4f} ± {avg_metrics['roc_auc_std']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
