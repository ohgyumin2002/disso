{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import shap \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "base_dir = r\"C:\\Users\\ChiappiniLab.Chiappini_Lab\\Desktop\\Sam\\20241129_solid_nN_1.3_2.4_mdck_siRNA_tnsfn_chlr\\20241129_solid_nN_2.4_mdck_siRNA_dataset\"\n",
    "dataset = base_dir + r\"\\solid_2.4_siRNA_cell_level.csv\"\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define morphological and intensity features\n",
    "cell_morph_features = [\n",
    "    'area', 'perimeter', 'major_axis_length', 'minor_axis_length', \n",
    "    'eccentricity', 'circularity', 'solidity', 'orientation'\n",
    "]\n",
    "\n",
    "nuclear_morph_features = ['nuclear_area', 'nuclear_perimeter', 'nuclear_major_axis_length', 'nuclear_minor_axis_length', \n",
    "    'nuclear_eccentricity', 'nuclear_circularity', 'nuclear_solidity', 'nuclear_orientation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_feature_suffixes = [ \n",
    "    'intensity_p10', 'intensity_p25', \n",
    "    'intensity_p50', 'intensity_p75', \n",
    "    'intensity_p90'\n",
    "] \n",
    "\n",
    "protein_channels = ['actin', 'caveolin', 'clathrin_hc', 'nuclei']\n",
    "\n",
    "feature_list = cell_morph_features + nuclear_morph_features + [f\"{ch}_{suffix}\" for ch in protein_channels for suffix in channel_feature_suffixes]\n",
    "\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells within 2nd and 98th percentiles and remove negative delivery\n",
    "cell_area = cell_area_min, cell_area_max = 234, 1927\n",
    "nuclear_area = nuclei_area_min, nuclei_area_max = 46, 315\n",
    "\n",
    "# Keep only cells in area range\n",
    "df_cell_filtered = df[\n",
    "    (df['area'] >= cell_area_min) &\n",
    "    (df['area'] <= cell_area_max) \n",
    "].copy()\n",
    "\n",
    "# Keep only nuclei in area range \n",
    "nuclei_threshold = (\n",
    "    (df_cell_filtered['nuclear_area'] >= nuclei_area_min) &\n",
    "    (df_cell_filtered['nuclear_area'] <= nuclei_area_max)\n",
    ")\n",
    "\n",
    "# For rows where the nuclei are out of range, set nucleus area to NaN\n",
    "nuclear_cols = ['nuclear_area', 'nuclear_perimeter', 'nuclear_major_axis_length', 'nuclear_minor_axis_length', \n",
    "    'nuclear_eccentricity', 'nuclear_circularity', 'nuclear_solidity', 'nuclear_orientation', \n",
    "    'nuclear_intensity_p10', 'nuclear_intensity_p25', 'nuclear_intensity_p50', \n",
    "    'nuclear_intensity_p75', 'nuclear_intensity_p90', ...]\n",
    "\n",
    "df_cell_filtered.loc[~nuclei_threshold, nuclear_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "#   Define binary target \n",
    "# -------------------------------\n",
    "\n",
    "# Define target\n",
    "df_cell_filtered['siRNA_category'] = np.where(\n",
    "    df_cell_filtered['siRNA_intensity_mean'] > 250,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(\"Unique siRNA_category values:\", df_cell_filtered['siRNA_category'].unique())\n",
    "print(\"Value counts:\\n\", df_cell_filtered['siRNA_category'].value_counts())\n",
    "\n",
    "# -------------------------------\n",
    "#   Define X, y, and images from the *same* df_cell_filtered\n",
    "# -------------------------------\n",
    "\n",
    "X = df_cell_filtered[feature_list].copy()\n",
    "y = df_cell_filtered['siRNA_category'].values\n",
    "images = df_cell_filtered['image_id'].values\n",
    "\n",
    "# Encode if needed (binary is not strictly necessary to encode, but okay):\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# -------------------------------\n",
    "#   Outer Cross-Validation Setup\n",
    "# -------------------------------\n",
    "outer_cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold_number, (train_idx, test_idx) in enumerate(outer_cv.split(X, y_encoded, groups=images), start=1):\n",
    "    y_test_fold = y_encoded[test_idx]\n",
    "    print(f\"Fold {fold_number}: n_test={len(y_test_fold)} -> Class distribution: {np.bincount(y_test_fold)}\")\n",
    "\n",
    "# TRAIN metrics\n",
    "fold_accuracies_train = []   \n",
    "fold_precisions_train = []   \n",
    "fold_recalls_train = []      \n",
    "fold_f1s_train = []          \n",
    "fold_aucs_train = []  \n",
    "\n",
    "# TEST metrics\n",
    "fold_accuracies_test = []\n",
    "fold_precisions_test = []\n",
    "fold_recalls_test = []\n",
    "fold_f1s_test = []\n",
    "fold_aucs_test = []\n",
    "\n",
    "\n",
    "# For aggregated ROC, we store all test labels and probabilities\n",
    "all_test_true = []\n",
    "all_test_proba = []\n",
    "\n",
    "# Track the best overall model (by test accuracy)\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "best_scaler = None\n",
    "\n",
    "# -------------------------------\n",
    "#   Cross-Validation and Hyperparameter Tuning\n",
    "# -------------------------------\n",
    "fold_number = 0\n",
    "for train_idx, test_idx in outer_cv.split(X, y_encoded, groups=images):\n",
    "    fold_number += 1\n",
    "    print(f\"\\n=== Outer Fold {fold_number} ===\")\n",
    "    print(f\"Fold {fold_number}: n_test={len(y_test_fold)} -> Class distribution: \"\n",
    "    f\"{np.bincount(y_test_fold)} (0s, 1s)\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define the Optuna objective\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'use_label_encoder': False,  # In newer xgboost versions, this is recommended\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "        \n",
    "        model = xgb.XGBClassifier(random_state=42, **params)\n",
    "        \n",
    "        # Inner CV for hyperparameter selection\n",
    "        inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        inner_scores = []\n",
    "        for inner_train_idx, inner_valid_idx in inner_cv.split(X_train_scaled, y_train):\n",
    "            X_inner_train = X_train_scaled[inner_train_idx]\n",
    "            y_inner_train = y_train[inner_train_idx]\n",
    "            X_inner_valid = X_train_scaled[inner_valid_idx]\n",
    "            y_inner_valid = y_train[inner_valid_idx]\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                model.fit(X_inner_train, y_inner_train)\n",
    "            \n",
    "            y_pred_inner = model.predict(X_inner_valid)\n",
    "            score = accuracy_score(y_inner_valid, y_pred_inner)\n",
    "            inner_scores.append(score)\n",
    "        \n",
    "        return np.mean(inner_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best parameters:\", best_params)\n",
    "\n",
    "    # Train the final model on this fold using the best parameters\n",
    "    best_model = xgb.XGBClassifier(\n",
    "        random_state=42, \n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        **best_params\n",
    "    )\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Evaluate Training Set (NEW)\n",
    "    # ---------------------------\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_train_prob = best_model.predict_proba(X_train_scaled)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_recall = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
    "\n",
    "    # ROC for training (positive class=1)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob[:, 1], pos_label=1)\n",
    "    train_roc_auc = auc(fpr_train, tpr_train)\n",
    "\n",
    "    fold_accuracies_train.append(train_accuracy)   \n",
    "    fold_precisions_train.append(train_precision)  \n",
    "    fold_recalls_train.append(train_recall)        \n",
    "    fold_f1s_train.append(train_f1)                \n",
    "    fold_aucs_train.append(train_roc_auc)          \n",
    "\n",
    "    # ---------------------------\n",
    "    # Evaluate Test Set\n",
    "    # ---------------------------\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    y_test_prob = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob[:, 1], pos_label=1)\n",
    "    test_roc_auc = auc(fpr_test, tpr_test)\n",
    "\n",
    "    # Store test metrics\n",
    "    fold_accuracies_test.append(test_accuracy)\n",
    "    fold_precisions_test.append(test_precision)\n",
    "    fold_recalls_test.append(test_recall)\n",
    "    fold_f1s_test.append(test_f1)\n",
    "    fold_aucs_test.append(test_roc_auc)\n",
    "\n",
    "    # Print immediate fold results\n",
    "    print(f\"Fold {fold_number} Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold_number} Test Accuracy:     {test_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold_number} Precision (Test):  {test_precision:.4f}\")\n",
    "    print(f\"Fold {fold_number} Recall (Test):     {test_recall:.4f}\")\n",
    "    print(f\"Fold {fold_number} F1-score (Test):   {test_f1:.4f}\")\n",
    "    print(f\"Fold {fold_number} ROC-AUC (Test):    {test_roc_auc:.4f}\")\n",
    "\n",
    "    # Accumulate for aggregated ROC (test only)\n",
    "    all_test_true.extend(y_test)\n",
    "    all_test_proba.extend(y_test_prob)\n",
    "\n",
    "    # Track best overall model based on test accuracy\n",
    "    if test_accuracy > best_overall_accuracy:\n",
    "        best_overall_accuracy = test_accuracy\n",
    "        best_overall_model = best_model\n",
    "        best_scaler = scaler\n",
    "\n",
    "# -------------------------------\n",
    "#   Aggregate & Print Results\n",
    "# -------------------------------\n",
    "print(\"\\n=== Cross-Validation Results (TRAIN) ===\")\n",
    "print(f\"Mean Train Accuracy:  {np.mean(fold_accuracies_train):.4f} ± {np.std(fold_accuracies_train):.4f}\")\n",
    "print(f\"Mean Train Precision: {np.mean(fold_precisions_train):.4f} ± {np.std(fold_precisions_train):.4f}\")\n",
    "print(f\"Mean Train Recall:    {np.mean(fold_recalls_train):.4f} ± {np.std(fold_recalls_train):.4f}\")\n",
    "print(f\"Mean Train F1-score:  {np.mean(fold_f1s_train):.4f} ± {np.std(fold_f1s_train):.4f}\")\n",
    "print(f\"Mean Train ROC-AUC:   {np.mean(fold_aucs_train):.4f} ± {np.std(fold_aucs_train):.4f}\")\n",
    "\n",
    "print(\"\\n=== Cross-Validation Results (TEST) ===\")\n",
    "print(f\"Mean Test Accuracy:  {np.mean(fold_accuracies_test):.4f} ± {np.std(fold_accuracies_test):.4f}\")\n",
    "print(f\"Mean Test Precision: {np.mean(fold_precisions_test):.4f} ± {np.std(fold_precisions_test):.4f}\")\n",
    "print(f\"Mean Test Recall:    {np.mean(fold_recalls_test):.4f} ± {np.std(fold_recalls_test):.4f}\")\n",
    "print(f\"Mean Test F1-score:  {np.mean(fold_f1s_test):.4f} ± {np.std(fold_f1s_test):.4f}\")\n",
    "print(f\"Mean Test ROC-AUC:   {np.mean(fold_aucs_test):.4f} ± {np.std(fold_aucs_test):.4f}\")\n",
    "\n",
    "print(f\"\\nBest overall test accuracy across folds: {best_overall_accuracy:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "#   Save the Best Model\n",
    "# -------------------------------\n",
    "joblib.dump((best_overall_model, best_scaler), \"best_xgb_model.pkl\")\n",
    "print(\"Best model saved to 'best_xgb_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"====== Aggregated ROC-AUC curve ====== \" \n",
    "\n",
    "# \"all_test_true\" is (N,) with 0/1\n",
    "# \"all_test_proba\" is (N,2)\n",
    "\n",
    "all_test_true = np.array(all_test_true)\n",
    "all_test_proba = np.array(all_test_proba)\n",
    "\n",
    "# ROC for positive class (1)\n",
    "fpr, tpr, _ = roc_curve(all_test_true, all_test_proba[:, 1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"Class 1 (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0,1], [0,1], \"k--\")  # Diagonal chance line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Class 1)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"====== Shapley results of best performing fold ====== \" \n",
    "\n",
    "# 1) Load your best model and scaler\n",
    "final_model, final_scaler = joblib.load(\"best_xgb_model.pkl\")\n",
    "print(\"Loaded best overall model and scaler from 'best_xgb_model.pkl'.\")\n",
    "\n",
    "# 2) Assume you have a test set (X_test, y_test) or a chosen subset\n",
    "#    For illustration, let's say X_test is already defined:\n",
    "# X_test = ...  # your DataFrame of test features\n",
    "\n",
    "# 3) Create a matrix of test values by applying the saved scaler\n",
    "test_matrix = final_scaler.transform(X_test)\n",
    "\n",
    "# 4) Create a SHAP explainer for the loaded model\n",
    "explainer = shap.TreeExplainer(final_model)\n",
    "\n",
    "# 5) Compute SHAP values for the test matrix\n",
    "shap_values = explainer.shap_values(test_matrix) \n",
    "print(\"Raw SHAP values shape/type:\", type(shap_values), \n",
    "      np.array(shap_values).shape if not isinstance(shap_values, list) else \"list of arrays\")\n",
    "\n",
    "# ----- Handle Multi-class or Extra Column if Needed -----\n",
    "# If shap_values is a list or has shape (n_classes, n_samples, n_features),\n",
    "# select a single class index, e.g. shap_values[0].\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "elif shap_values.ndim == 3:\n",
    "    # Select the SHAP values for a specific class (e.g., class 0) across all samples\n",
    "    shap_values = shap_values[:, :, 1]\n",
    "\n",
    "# If there's an extra column for the base value, remove it\n",
    "if shap_values.shape[1] == test_matrix.shape[1] + 1:\n",
    "    shap_values = shap_values[:, :-2]\n",
    "\n",
    "# Double-check the shape matches (n_samples, n_features)\n",
    "assert shap_values.shape[0] == test_matrix.shape[0], \"Row mismatch!\"\n",
    "assert shap_values.shape[1] == test_matrix.shape[1], \"Column mismatch!\"\n",
    "\n",
    "# 6) Plot the SHAP beeswarm summary\n",
    "#    Optionally convert your test_matrix back to a DataFrame with column names\n",
    "feature_names = X_test.columns.tolist()  # or however you store your feature list\n",
    "shap.summary_plot(shap_values, test_matrix, feature_names=feature_names)\n",
    "                                                                                                                                                                                                                                                                                                                                             \n",
    "# Optionally show the plot inline if in a notebook\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
